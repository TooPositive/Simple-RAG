# üé¨ Demo Preparation Guide
## Simple-RAG v2.0 - Capstone Presentation

This guide helps you prepare an excellent Capstone demo video using the materials provided.

---

## üìÅ Demo Materials Provided

### 1. **CAPSTONE_DEMO_SCRIPT.md** ‚≠ê
**The main presentation script** - Use this as your speaking guide!

Contains:
- ‚úÖ Complete 5-minute demo flow
- ‚úÖ What to say and when
- ‚úÖ What to show on screen
- ‚úÖ Timing for each section
- ‚úÖ Speaker notes and tips
- ‚úÖ Common questions to prepare for

**Start here!** This is your complete guide.

---

### 2. **Architecture Diagrams** (Mermaid Format)

All diagrams are in `.mmd` format - render them at https://mermaid.live

#### **architecture.mmd**
- Main system overview
- LangGraph workflow
- All components and data flow
- **Use this for the architecture overview section**

#### **architecture_components.mmd**
- Detailed component breakdown
- Refactored modules structure
- Shows the 81% code reduction
- **Use this to explain production quality**

#### **architecture_dataflow.mmd**
- Sequence diagram showing query processing
- Token optimization in action
- Demonstrates 3 different query types
- **Use this to explain efficiency**

#### **capstone_requirements_mapping.mmd**
- Maps Capstone requirements to implementation
- Shows evidence and results
- Production quality bonus features
- **Use this to show requirement fulfillment**

---

### 3. **Analysis Documents**

#### **RESPONSE_QUALITY_ANALYSIS.md**
- Detailed analysis of all 4 demo queries
- Shows scores (67-93/100)
- Token savings breakdown
- Component validation
- **Use this for reference during prep**

#### **MERGE_STATUS_REPORT.md**
- Confirms all systems working
- Test results (33/33 passing)
- Before/after comparison
- **Use this to show technical rigor**

---

## üéØ Quick Start: 3-Step Preparation

### Step 1: Read the Script (30 minutes)
1. Open `CAPSTONE_DEMO_SCRIPT.md`
2. Read through the entire demo flow
3. Note the timing for each section
4. Familiarize yourself with what to emphasize

### Step 2: Prepare Visuals (30 minutes)
1. Go to https://mermaid.live
2. Paste each `.mmd` file and render
3. Export as PNG or SVG
4. Save for your video recording
5. Alternative: Keep mermaid.live open in browser tabs during recording

### Step 3: Practice the Demo (30 minutes)
1. Open terminal with `interactive_agent.py`
2. Follow the demo script queries:
   - "Hi"
   - "What is this repo about?"
   - "Where do we use langgraph?"
   - "Write me a linkedin post about this repo and mention that Mr Tomato inspired me to do it"
3. Practice timing (aim for 5 minutes total)
4. Record yourself once as practice

---

## üé• Recording Setup Checklist

### Before Recording:

**Terminal Setup:**
- [ ] Clean terminal (no previous output)
- [ ] Large font (16-18pt for readability)
- [ ] Full screen or wide terminal window
- [ ] Activate virtual environment: `.venv/bin/python`

**Browser Setup:**
- [ ] Tab 1: Mermaid.live with architecture.mmd
- [ ] Tab 2: Mermaid.live with architecture_components.mmd
- [ ] Tab 3: Mermaid.live with architecture_dataflow.mmd
- [ ] Tab 4: Your GitHub repository
- [ ] Close other tabs (avoid distractions)

**Code Editor:**
- [ ] Open VS Code or your preferred editor
- [ ] Have these files in tabs:
  - `src/agent/orchestrator.py`
  - `src/agent/nodes/generator.py`
  - `src/agent/nodes/reflector.py`
  - `src/agent/nodes/reasoner.py`
- [ ] Zoom in for readability (125-150%)

**Test the Agent:**
- [ ] Run: `.venv/bin/python interactive_agent.py`
- [ ] Verify `.env` file is configured
- [ ] Test one query to ensure LLM is working
- [ ] Exit and restart for clean demo

---

## üé¨ Recording Tips

### Video Quality:
- **Resolution**: 1920x1080 (Full HD) minimum
- **Frame rate**: 30 fps minimum
- **Audio**: Clear microphone, quiet environment
- **Screen recording tool**:
  - Mac: QuickTime Player (File ‚Üí New Screen Recording)
  - Windows: OBS Studio (free)
  - Linux: SimpleScreenRecorder

### Speaking Tips:
- **Pace**: Slow and clear (you know it well, viewers don't!)
- **Energy**: Enthusiastic but professional
- **Pauses**: After each agent response, pause 2-3 seconds
- **Emphasis**: When mentioning key metrics (93/100, 87% savings, etc.)

### Visual Tips:
- **Mouse movement**: Slow and deliberate
- **Scrolling**: Pause to let viewers read
- **Highlighting**: Use mouse to point at important sections
- **Transitions**: Smooth changes between terminal/browser/code

---

## üìä Demo Flow Summary

**0:00-0:30** - Opening hook
- Introduce yourself and the project
- Mention Ciklum AI Academy Capstone

**0:30-2:30** - Live Demo (4 queries)
1. "Hi" - Shows token optimization (87% savings)
2. "What is this repo about?" - Shows reasoning & reflection (93/100 score)
3. "Where do we use langgraph?" - Shows caching (85% savings)
4. "LinkedIn post" - Shows practical application

**2:30-4:30** - Architecture Deep Dive
- Show architecture.mmd diagram
- Explain 5 Capstone requirements
- Highlight production quality (81% code reduction)
- Mention token optimizations

**4:30-5:00** - Closing
- Summarize requirement fulfillment
- Thank Ciklum AI Academy
- Show GitHub link

---

## üéØ What to Emphasize

### Top 5 Key Points:
1. **93/100 Quality Score** - Production-grade output
2. **Reasoning & Reflection** - Core Capstone requirement
3. **87% Token Savings** - Intelligent optimization
4. **81% Code Reduction** - Engineering excellence
5. **All Requirements Met** - Complete implementation

### Technical Highlights:
- Multi-step chain-of-thought reasoning
- Self-evaluation and quality assessment
- Intelligent caching across queries
- Autonomous tool selection
- Evidence-based responses with citations

### Professional Touches:
- 33/33 tests passing
- SOLID principles applied
- Dependency injection for testing
- Modular, reusable components
- Graceful error handling

---

## ‚ùì Anticipated Questions & Answers

**Q: Why LangGraph instead of CrewAI?**
A: "LangGraph provides fine-grained control over state flow and conditional routing, which is essential for implementing the self-reflection loops required by the Capstone."

**Q: How does the caching work?**
A: "Repository analysis is cached in the AgentState after the first query. Follow-up queries check for cached data and reuse it, saving ~5000 tokens per query."

**Q: What's the most challenging part?**
A: "Balancing token efficiency with output quality. We achieved this through intelligent skip logic - trivial queries skip reasoning and reflection, saving up to 87% of tokens while maintaining appropriate responses."

**Q: How would you deploy this to production?**
A: "Package as a Docker container with Azure OpenAI configuration, add a FastAPI REST endpoint for programmatic access, and implement session-based caching with Redis for multi-user scenarios."

**Q: What would you add next?**
A: "Three key enhancements: (1) Memory persistence across sessions using vector storage, (2) Multi-repository support for comparing codebases, and (3) A web interface for non-technical users."

---

## üîß Troubleshooting

### If agent gives template responses:
- Check `.env` file exists (copy from `.env.example`)
- Verify Azure OpenAI credentials are correct
- Confirm `LLM_MODEL_NAME` matches your deployment

### If scores are different:
- That's OK! LLM responses vary slightly
- Focus on the process, not exact numbers
- Scores in 70-95 range are all excellent

### If you run out of time:
- Use the "Alternative Demo Flow" in CAPSTONE_DEMO_SCRIPT.md
- Focus on Query 2 (repo analysis) - shows all features
- Shorten architecture section to 1 minute

---

## üéâ Final Checklist Before Recording

**Content:**
- [ ] I've read the full demo script
- [ ] I understand what each query demonstrates
- [ ] I know what to emphasize
- [ ] I've prepared answers to common questions

**Technical:**
- [ ] Terminal is set up with large font
- [ ] Agent is working (tested with one query)
- [ ] Diagrams are rendered and ready
- [ ] GitHub repo is accessible

**Recording:**
- [ ] Microphone tested (clear audio)
- [ ] Screen recording software ready
- [ ] Browser tabs prepared
- [ ] Quiet environment
- [ ] No notifications (turn off Slack, email, etc.)

**Practice:**
- [ ] I've done a practice run
- [ ] Timing is under 6 minutes (leaves buffer)
- [ ] I know when to pause for viewers to read
- [ ] I'm comfortable with the flow

---

## üì§ After Recording

**Video Review:**
1. Watch your recording fully
2. Check audio quality
3. Verify all text is readable
4. Ensure no personal info visible
5. Confirm you mentioned Ciklum AI Academy

**Upload:**
1. YouTube (unlisted) or Loom
2. Add title: "Simple-RAG v2.0 - AI Agentic System | Ciklum AI Academy Capstone"
3. Add description with GitHub link
4. Get shareable link

**LinkedIn Post:**
1. Use the agent-generated post (from query 4)
2. Add your video link
3. Tag @Ciklum
4. Use hashtags from the agent's post

**Submission:**
1. Complete the Capstone submission form
2. Include: GitHub link, video link, LinkedIn post link
3. Double-check all links are public
4. Submit!

---

## üåü You've Got This!

You've built something impressive:
- ‚úÖ Production-quality code
- ‚úÖ All Capstone requirements met
- ‚úÖ Excellent performance (93/100)
- ‚úÖ Smart optimizations (87% savings)
- ‚úÖ Clean architecture

**Now just show it off with confidence!** üöÄ

The preparation materials are comprehensive, the script is detailed, and your system works beautifully. Follow this guide, practice once or twice, and you'll deliver an excellent demo.

**Good luck!** üéâ

---

## üìû Quick Reference

**Demo Queries (in order):**
1. `Hi`
2. `What is this repo about?`
3. `Where do we use langgraph?`
4. `Write me a linkedin post about this repo and mention that Mr Tomato inspired me to do it`

**Key Metrics to Mention:**
- 93/100 quality score
- 87% token savings
- 81% code reduction
- 33/33 tests passing
- 169 code symbols extracted

**Mermaid Diagrams to Show:**
1. architecture.mmd - Main overview
2. architecture_components.mmd - Shows refactoring
3. capstone_requirements_mapping.mmd - Shows fulfillment

**Target Duration:** 5 minutes (¬± 30 seconds)
